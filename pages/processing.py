import streamlit as st
import cv2
import time
import numpy as np
import mediapipe as mp # Import here as well for clarity within the page's scope
from collections import Counter # Need Counter for classify_reps summary
import os
import pandas as pd

# Import functions from our utils package
from utils.pose_detector import PoseDetector
from utils.feature_extractor import extract_features, calculate_angle as feature_calc_angle # Rename if there's a conflict
from utils.model_loader import load_model
from utils.ui_drawer import draw_ui, draw_class_probabilities, draw_prediction_on_ear, to_pixel_coords
from utils.video_processor import get_video_source, release_video_source, mirror_frame
from utils.rep_logic import update_rep_counter, classify_reps, REP_CLASSES # Import classify_reps and REP_CLASSES

mp_pose = mp.solutions.pose # Need to redefine for use with Landmark enums

def app():
    st.title("üìä ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• & ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•")
    st.markdown("---")

    # Check if necessary data from Feature Selection is available
    if 'video_source' not in st.session_state or \
       'selected_arm' not in st.session_state or \
       'selected_model_type' not in st.session_state or \
       'model_path' not in st.session_state:
        st.warning("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•' ‡∏Å‡πà‡∏≠‡∏ô.")
        if st.button("‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"):
            st.session_state.current_page_option = "Feature Selection" # Correct page name for option_menu
            st.rerun()
        return # Stop execution if settings are not found

    video_source = st.session_state.video_source
    video_name = st.session_state.uploaded_video_name
    selected_arm = st.session_state.selected_arm
    selected_model_type = st.session_state.selected_model_type
    model_file_path = st.session_state.model_path

    st.write(f"**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** {video_source} {video_name}")
    st.write(f"**‡πÅ‡∏Ç‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:** {selected_arm}")
    st.write(f"**‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:** {selected_model_type} {model_file_path}")

    # Load the selected model
    model = load_model(model_file_path)
    if model is None:
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á.")
        if st.button("‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"):
            st.session_state.current_page_option = "Feature Selection" # Correct page name
            st.rerun()
        return
    
    # Initialize MediaPipe Pose detector
    pose_detector = PoseDetector()

    # Streamlit video placeholder
    st_frame = st.empty()

    # Control buttons
    col1, col2 = st.columns(2)
    start_button = col1.button("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
    stop_button = col2.button("‡∏´‡∏¢‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")

    # Initial states for rep counting and classification
    counter = 0
    stage = None
    current_rep_start = None
    rep_segments = []            # List to store (start_frame, end_frame) for each rep
    frame_classifications = []   # List to store class label for each frame
    frame_idx = 0

    # Variable to store temporary file path
    temp_video_path = None # Initialize outside the if block

    if start_button:
        st.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")
        # Get the uploaded_video_file object from session state
        uploaded_video_file_obj = st.session_state.get('uploaded_video_file', None)
        
        # Call get_video_source, now it returns cap and temp_file_path
        cap, temp_video_path = get_video_source(video_source, uploaded_video_file_obj)

        if cap is None:
            st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î.")
            # Ensure temp_video_path is cleaned up if it was created before error
            if temp_video_path and os.path.exists(temp_video_path):
                 os.remove(temp_video_path)
            return

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if video_source == "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠" else 0
        progress_bar = st.progress(0) if total_frames > 0 else None

        processing_active = True
        while cap.isOpened() and processing_active:
            ret, frame = cap.read()
            if not ret:
                break

            # --- Mirroring Logic ---
            if selected_arm == "‡∏Ç‡∏ß‡∏≤ (Right Arm)":
                frame = mirror_frame(frame)

            # Get frame dimensions for drawing
            frame_height, frame_width, _ = frame.shape

            # 1. Pose Detection
            image, results = pose_detector.detect(frame)
            
            # Default values if no pose is detected or error
            body_language_class = "no_pose" # Default class if no pose is detected
            body_language_prob = np.zeros(len(model.classes_)) if hasattr(model, 'classes_') else np.zeros(len(REP_CLASSES))

            if results.pose_landmarks:
                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡πâ features ‡πÄ‡∏õ‡πá‡∏ô None ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤
                features = None 
                
                try:
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà extract_features ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
                    feature_type_str = ""
                    if selected_model_type == "‡πÇ‡∏°‡πÄ‡∏î‡∏• 33 ‡∏à‡∏∏‡∏î (Raw MediaPipe Landmarks)":
                        feature_type_str = "33_points"
                    elif selected_model_type == "‡πÇ‡∏°‡πÄ‡∏î‡∏• 17 ‡∏à‡∏∏‡∏î (Selected MediaPipe Landmarks)":
                        feature_type_str = "17_points"
                    elif selected_model_type == "‡πÇ‡∏°‡πÄ‡∏î‡∏• 17 ‡∏à‡∏∏‡∏î + Features (‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á/‡∏°‡∏∏‡∏°)":
                        feature_type_str = "17_points_plus_angles"
                    else:
                        st.warning(f"Model type '{selected_model_type}' not recognized by feature extractor.")
                        body_language_class = "unrecognized_model_type"
                        # features ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô None
                        
                    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á features ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡∏ñ‡πâ‡∏≤ feature_type_str ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                    if feature_type_str: # Only attempt extraction if feature_type_str is valid
                        features = extract_features(results.pose_landmarks.landmark, model_type=feature_type_str)
                    
                    if features is not None and not features.empty:
                        # Predict class
                        body_language_class = model.predict(features)[0]
                        body_language_prob = model.predict_proba(features)[0]

                        # --- NEW CODE FOR SHOULDER ANGLE DISPLAY ---
                        try:
                            landmarks = results.pose_landmarks.landmark
                            
                            # Determine which arm to display based on selected_arm
                            if selected_arm == "‡∏ã‡πâ‡∏≤‡∏¢ (Left Arm)":
                                target_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
                                target_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                                target_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                            elif selected_arm == "‡∏Ç‡∏ß‡∏≤ (Right Arm)":
                                # If mirroring is on, the "RIGHT" landmarks visually appear on the left side of the frame.
                                # But we still reference them as RIGHT_... in MediaPipe.
                                target_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
                                target_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                                target_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]
                            else: # Default to Left Arm for display if "Both Arms" or unspecified
                                target_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
                                target_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                                target_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]

                            # Ensure all points are detected and visible before calculating/drawing
                            if all(p is not None for p in [target_hip, target_shoulder, target_elbow]):
                                # Calculate the angle at the shoulder (Hip-Shoulder-Elbow)
                                shoulder_angle = feature_calc_angle(target_hip, target_shoulder, target_elbow)

                                # Draw vectors (Hip-Shoulder, Shoulder-Elbow)
                                # Using to_pixel_coords for drawing
                                cv2.line(image, to_pixel_coords(target_shoulder, frame_width, frame_height), 
                                                to_pixel_coords(target_hip, frame_width, frame_height), (0, 255, 0), 10) # Green for Hip-Shoulder
                                cv2.line(image, to_pixel_coords(target_shoulder, frame_width, frame_height), 
                                                to_pixel_coords(target_elbow, frame_width, frame_height), (0, 0, 255), 10) # Blue for Shoulder-Elbow
                                
                                # Display the shoulder angle near the shoulder
                                angle_display_coords = to_pixel_coords(target_shoulder, frame_width, frame_height)
                                cv2.putText(image, f"Sh. Angle: {int(shoulder_angle)}", 
                                            (angle_display_coords[0] + 20, angle_display_coords[1] - 20), # Offset text slightly
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA) # White text
                            else:
                                st.write("Warning: Some shoulder/hip/elbow landmarks are not visible for angle display.")
                        except Exception as angle_display_e:
                            # Catch specific errors if landmarks are not found for display
                            st.warning(f"Error displaying shoulder angle or vectors: {angle_display_e}")

                        # --- Repetition Counting Logic ---
                        angle_to_track = None
                        try:
                            # ... (‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì angle_to_track ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
                            if selected_arm == "‡∏ã‡πâ‡∏≤‡∏¢ (Left Arm)":
                                l_shoulder = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, 
                                              results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                                l_elbow = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, 
                                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                                l_hip = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP.value].x, 
                                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP.value].y]
                                angle_to_track = feature_calc_angle(l_hip, l_shoulder, l_elbow)
                            elif selected_arm == "‡∏Ç‡∏ß‡∏≤ (Right Arm)":
                                r_shoulder = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, 
                                              results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                                r_elbow = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, 
                                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]
                                r_hip = [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP.value].x, 
                                           results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
                                angle_to_track = feature_calc_angle(r_hip, r_shoulder, r_elbow)
                            
                            if angle_to_track is not None:
                                stage, counter, current_rep_start, rep_segments = update_rep_counter(
                                    angle_to_track, stage, counter, frame_idx, current_rep_start, rep_segments
                                )
                        except Exception as angle_e:
                            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏£‡∏≠‡∏ö‡πÑ‡∏î‡πâ: {angle_e}. ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Landmark ‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ.")
                            pass
                        
                    else: # ‡∏ñ‡πâ‡∏≤ features ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠ Empty DataFrame ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á
                        st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (Features) ‡∏à‡∏≤‡∏Å Landmark ‡πÑ‡∏î‡πâ ‡∏´‡∏£‡∏∑‡∏≠ features ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤.")
                        body_language_class = "no_features" 
                        # body_language_prob ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (zeros)
                except Exception as e:
                    st.warning(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• AI: {e}")
                    body_language_class = "error_processing" 
            else: # ‡∏ñ‡πâ‡∏≤ results.pose_landmarks ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡∏¢
                body_language_class = "no_pose" 
                # body_language_prob ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (zeros)

            frame_classifications.append(body_language_class)

            # 3. Drawing UI
            image = pose_detector.draw_landmarks(image, results)
            image = draw_ui(image, counter, stage)
            if results.pose_landmarks: # Only draw prediction if landmarks are present
                image = draw_prediction_on_ear(image, results, body_language_class, body_language_prob)
                try:
                    class_names_for_display = model.classes_ if hasattr(model, 'classes_') else REP_CLASSES # Use REP_CLASSES as fallback
                    image = draw_class_probabilities(image, class_names_for_display, body_language_prob, frame_width, frame_height)
                except Exception as e:
                    # print(f"Could not draw class probabilities: {e}")
                    pass 

            # Display the processed frame
            st_frame.image(image, channels="BGR", use_container_width=True)

            # Update progress bar
            if progress_bar:
                current_progress = int((frame_idx / total_frames) * 100)
                progress_bar.progress(current_progress)

            frame_idx += 1
            time.sleep(0.01) # Small delay to prevent overwhelming CPU/GPU

            # Check for stop button press inside the loop
            if stop_button: # This checks the button state on each rerun
                processing_active = False
                break # Exit the loop if stop button is pressed

        release_video_source(cap)
        st.success("‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

        # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ (‡πÉ‡∏´‡∏°‡πà) ---
        st.subheader("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ")
        patient_info = st.session_state.get('patient_info', {}) # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ
        
        if patient_info:
            # ‡πÉ‡∏ä‡πâ st.columns ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏ß‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            col_p1, col_p2 = st.columns(2)
            with col_p1:
                st.markdown(f"**‡∏£‡∏´‡∏±‡∏™‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ:** `{patient_info.get('‡∏£‡∏´‡∏±‡∏™‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ', 'N/A')}`")
                st.markdown(f"**‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•:** `{patient_info.get('‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', 'N/A')}`")
                st.markdown(f"**‡∏≠‡∏≤‡∏¢‡∏∏:** `{patient_info.get('‡∏≠‡∏≤‡∏¢‡∏∏', 'N/A')}` ‡∏õ‡∏µ")
            with col_p2:
                st.markdown(f"**‡πÄ‡∏û‡∏®:** `{patient_info.get('‡πÄ‡∏û‡∏®', 'N/A')}`")
                st.markdown(f"**‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå:** `{patient_info.get('‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå', 'N/A')}`")
            
            st.markdown(f"**‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢/‡∏≠‡∏≤‡∏Å‡∏≤‡∏£:** `{patient_info.get('‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢/‡∏≠‡∏≤‡∏Å‡∏≤‡∏£', 'N/A')}`")
        else:
            st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ 'Register'.")
        st.markdown("---")
        
         # --- ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà) ---
        st.subheader("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á")
        
        if rep_segments:
            rep_results, summary = classify_reps(frame_classifications, rep_segments, class_labels=model.classes_ if hasattr(model, 'classes_') else REP_CLASSES)
            
            # ‡πÉ‡∏ä‡πâ st.metric ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            st.metric(label="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", value=f"{len(rep_results)} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
            st.markdown("---")

            # ‡πÉ‡∏ä‡πâ st.expander ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° "‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
            with st.expander("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö"):
                if rep_results:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö
                    rep_df = pd.DataFrame({
                        "‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà": [i for i in range(1, len(rep_results) + 1)],
                        "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á": rep_results
                    })
                    st.table(rep_df) # ‡πÉ‡∏ä‡πâ st.table ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö.")
            
            st.markdown("---")

            # ‡πÉ‡∏ä‡πâ st.expander ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö "‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°"
            with st.expander("‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°"):
                if summary:
                    summary_df = pd.DataFrame(summary.items(), columns=["‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á", "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á"])
                    st.dataframe(summary_df.set_index("‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á")) # ‡πÉ‡∏ä‡πâ st.dataframe ‡∏ó‡∏µ‡πà‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤
                else:
                    st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°.")
        else:
            st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏´‡∏ß‡∏ó‡∏µ‡πà‡∏ô‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ")
        st.markdown("---")
        # --- ‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ---